{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%run ridges.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette('deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgs01 = pd.concat(pd.read_csv(filename, sep='\\t', header=None, names=['community', 'org_id'])\n",
    "                  for filename in glob('../communities/bin_rnd_01/*.tsv'))\n",
    "orgs01[\"size\"] = orgs01[\"community\"].apply(lambda x: int(x.split(\"_\")[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgs001 = pd.concat(pd.read_csv(filename, sep='\\t', header=None, names=['community', 'org_id'])\n",
    "                  for filename in glob('../communities/bin_rnd_001/*.tsv'))\n",
    "orgs001[\"size\"] = orgs001[\"community\"].apply(lambda x: int(x.split(\"_\")[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [2,4,6,8,10,15,20,25,30,40]\n",
    "orgs01 = orgs01[orgs01[\"size\"].isin(sizes)]\n",
    "orgs001 = orgs001[orgs001[\"size\"].isin(sizes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_csv('../data/emp_150bp_filtered.tsv', sep='\\t')\n",
    "\n",
    "samples['bin_value'] = 1\n",
    "samples['log_value'] = np.log10(samples['value'])\n",
    "\n",
    "samples_wide = pd.pivot_table(samples, index='org_id', columns='sample',\n",
    "                              values='bin_value', fill_value=0)\n",
    "del samples['bin_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge co-ocurrence and composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(cooc):\n",
    "\n",
    "    cooc['value'] = 1\n",
    "    cooc_wide = pd.pivot_table(cooc, index='org_id', columns='community',\n",
    "                               values='value', fill_value=0)\n",
    "    del cooc['value']\n",
    "\n",
    "    common = sorted(set(samples_wide.index) & set(cooc_wide.index))\n",
    "    samples_common = samples_wide.loc[common,:]\n",
    "    cooc_common = cooc_wide.loc[common,:]\n",
    "\n",
    "    cooc_comms_wide = cooc_common.T.dot(samples_common)\n",
    "    cooc_comms_bin = cooc_comms_wide.eq(cooc_wide.sum(axis=0), axis=0).astype(int)\n",
    "    cooc_comms = cooc_comms_bin.unstack().reset_index()\n",
    "    cooc_comms = cooc_comms[cooc_comms[0] > 0]\n",
    "    cooc_comms.drop(columns=[0], inplace=True)\n",
    "    \n",
    "    cooc_comms = pd.merge(cooc_comms, cooc, on=\"community\")\n",
    "    cooc_comms = pd.merge(cooc_comms, samples, on=[\"sample\", \"org_id\"])\n",
    "    \n",
    "    return cooc_comms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data01 = merge_data(orgs01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data001 = merge_data(orgs001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimate cumulative abundance of co-occurring communities per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_01 = data01.groupby([\"sample\", \"community\", \"size\"], as_index=False).agg({\"value\": sum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_001 = data001.groupby([\"sample\", \"community\", \"size\"], as_index=False).agg({\"value\": sum})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimate abundance of random sub-communities per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def random_subsamples(df):\n",
    "    reps = 100\n",
    "    tmp = []\n",
    "    idx_samples = samples.set_index(\"sample\")\n",
    "\n",
    "    for size, group in df.groupby(\"size\"):\n",
    "        samples_i = group[\"sample\"].drop_duplicates()\n",
    "        for s_id in samples_i:\n",
    "            values = list(idx_samples.loc[s_id,\"value\"])\n",
    "            for rep in range(reps):\n",
    "                value = sum(sample(values, size))\n",
    "                tmp.append((s_id, size, rep, value))\n",
    "\n",
    "    return pd.DataFrame(tmp, columns=[\"sample\", \"size\", \"rep\", \"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_01 = random_subsamples(data01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_001 = random_subsamples(data001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_01[\"type\"] = 'bin_rnd_01'\n",
    "sum_001[\"type\"] = 'bin_rnd_001'\n",
    "rnd_01[\"type\"] = 'random'\n",
    "rnd_001[\"type\"] = 'random'\n",
    "\n",
    "merged = pd.concat([sum_01[[\"sample\", \"size\", \"type\", \"value\"]],\n",
    "                    sum_001[[\"sample\", \"size\", \"type\", \"value\"]],\n",
    "                    rnd_01[[\"sample\", \"size\", \"type\", \"value\"]],\n",
    "                    rnd_001[[\"sample\", \"size\", \"type\", \"value\"]]])\n",
    "\n",
    "merged[\"log_value\"] = np.log10(merged[\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = ridges(merged, \"log_value\", (-4.4,0.1), \"subpopulation abundance\")\n",
    "axs[-1].set_xticks([-4, -3, -2, -1, 0])\n",
    "axs[-1].set_xticklabels(['0.01%', '0.1%','1%', '10%', '100%'])\n",
    "plt.savefig(\"../figures/fig_2d.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
